  File "DNNRegressor-Example.py", line 169
SyntaxError: Non-ASCII character '\xc3' in file DNNRegressor-Example.py on line 169, but no encoding declared; see http://python.org/dev/peps/pep-0263/ for details
INFO:root:Tensorflow 1.8.0
INFO:root:Saving to /home/hornberger/MasterarbeitTobias/models/Aug13ev/weiz2
INFO:root:loading data from store
INFO:root:Train the DNN Regressor...

(118926, 10) (118926, 2)
(13214, 10) (13214, 2)
we are making progress: 0
eval: {'average_loss': 3.2570016, 'loss': 3188.0015, 'global_step': 126000}
we are making progress: 10
eval: {'average_loss': 3.2552128, 'loss': 3186.2505, 'global_step': 128500}
we are making progress: 20
eval: {'average_loss': 3.2041283, 'loss': 3136.2483, 'global_step': 131000}
we are making progress: 30
eval: {'average_loss': 3.1889749, 'loss': 3121.4158, 'global_step': 133500}
we are making progress: 40
eval: {'average_loss': 3.1651263, 'loss': 3098.0725, 'global_step': 136000}
we are making progress: 50
eval: {'average_loss': 3.1405425, 'loss': 3074.0095, 'global_step': 138500}
we are making progress: 60
eval: {'average_loss': 3.1251948, 'loss': 3058.987, 'global_step': 141000}
we are making progress: 70
eval: {'average_loss': 3.1025147, 'loss': 3036.7874, 'global_step': 143500}
we are making progress: 80
eval: {'average_loss': 3.0832968, 'loss': 3017.9766, 'global_step': 146000}
we are making progress: 90
eval: {'average_loss': 3.0596638, 'loss': 2994.8442, 'global_step': 148500}
we are making progress: 100
eval: {'average_loss': 3.0409565, 'loss': 2976.5332, 'global_step': 151000}
we are making progress: 110
eval: {'average_loss': 3.022113, 'loss': 2958.089, 'global_step': 153500}
we are making progress: 120
eval: {'average_loss': 3.029227, 'loss': 2965.0525, 'global_step': 156000}
we are making progress: 130
eval: {'average_loss': 3.003077, 'loss': 2939.4563, 'global_step': 158500}
we are making progress: 140
eval: {'average_loss': 2.9657762, 'loss': 2902.9456, 'global_step': 161000}
we are making progress: 150
eval: {'average_loss': 2.9528801, 'loss': 2890.323, 'global_step': 163500}
we are making progress: 160
eval: {'average_loss': 2.9301238, 'loss': 2868.0486, 'global_step': 166000}
we are making progress: 170
eval: {'average_loss': 2.913021, 'loss': 2851.308, 'global_step': 168500}
we are making progress: 180
eval: {'average_loss': 2.9096448, 'loss': 2848.0034, 'global_step': 171000}
we are making progress: 190
eval: {'average_loss': 2.888094, 'loss': 2826.9092, 'global_step': 173500}
we are making progress: 200
eval: {'average_loss': 2.8753784, 'loss': 2814.463, 'global_step': 176000}
we are making progress: 210
eval: {'average_loss': 2.8599305, 'loss': 2799.3423, 'global_step': 178500}
we are making progress: 220
eval: {'average_loss': 2.849067, 'loss': 2788.709, 'global_step': 181000}
we are making progress: 230
eval: {'average_loss': 2.8283663, 'loss': 2768.4468, 'global_step': 183500}
we are making progress: 240
eval: {'average_loss': 2.8304625, 'loss': 2770.4985, 'global_step': 186000}
we are making progress: 250
eval: {'average_loss': 2.8043401, 'loss': 2744.9297, 'global_step': 188500}
we are making progress: 260
eval: {'average_loss': 2.7948027, 'loss': 2735.5942, 'global_step': 191000}
we are making progress: 270
eval: {'average_loss': 2.7786644, 'loss': 2719.7979, 'global_step': 193500}
we are making progress: 280
eval: {'average_loss': 2.7803702, 'loss': 2721.4675, 'global_step': 196000}
we are making progress: 290
eval: {'average_loss': 2.796654, 'loss': 2737.4062, 'global_step': 198500}
we are making progress: 300
eval: {'average_loss': 2.7615745, 'loss': 2703.07, 'global_step': 201000}
we are making progress: 310
eval: {'average_loss': 2.7363172, 'loss': 2678.348, 'global_step': 203500}
we are making progress: 320
eval: {'average_loss': 2.7269938, 'loss': 2669.222, 'global_step': 206000}
we are making progress: 330
eval: {'average_loss': 2.7218277, 'loss': 2664.1653, 'global_step': 208500}
we are making progress: 340
eval: {'average_loss': 2.7124481, 'loss': 2654.9844, 'global_step': 211000}
we are making progress: 350
eval: {'average_loss': 2.707815, 'loss': 2650.4495, 'global_step': 213500}
we are making progress: 360
eval: {'average_loss': 2.6926832, 'loss': 2635.6384, 'global_step': 216000}
we are making progress: 370
eval: {'average_loss': 2.6820352, 'loss': 2625.2158, 'global_step': 218500}
we are making progress: 380
eval: {'average_loss': 2.6805649, 'loss': 2623.7766, 'global_step': 221000}
we are making progress: 390
eval: {'average_loss': 2.664427, 'loss': 2607.9807, 'global_step': 223500}
we are making progress: 400
eval: {'average_loss': 2.6594093, 'loss': 2603.069, 'global_step': 226000}
we are making progress: 410
eval: {'average_loss': 2.658701, 'loss': 2602.376, 'global_step': 228500}
we are making progress: 420
eval: {'average_loss': 2.647072, 'loss': 2590.9934, 'global_step': 231000}
we are making progress: 430
eval: {'average_loss': 2.6439717, 'loss': 2587.9587, 'global_step': 233500}
we are making progress: 440
eval: {'average_loss': 2.636307, 'loss': 2580.4563, 'global_step': 236000}
we are making progress: 450
eval: {'average_loss': 2.6333625, 'loss': 2577.5745, 'global_step': 238500}
we are making progress: 460
eval: {'average_loss': 2.6243136, 'loss': 2568.717, 'global_step': 241000}
we are making progress: 470
eval: {'average_loss': 2.609667, 'loss': 2554.3809, 'global_step': 243500}
we are making progress: 480
eval: {'average_loss': 2.6042018, 'loss': 2549.0312, 'global_step': 246000}
we are making progress: 490
eval: {'average_loss': 2.59843, 'loss': 2543.3816, 'global_step': 248500}
INFO:root:Tensorflow 1.8.0
INFO:root:Saving to /home/hornberger/MasterarbeitTobias/models/Aug13ev/weiz2
INFO:root:loading data from store
INFO:root:Train the DNN Regressor...

INFO:root:eval: {'average_loss': 2.600317, 'loss': 2545.2288, 'global_step': 251000}
INFO:root:eval: {'average_loss': 2.591195, 'loss': 2536.3, 'global_step': 253500}
INFO:root:eval: {'average_loss': 2.5817437, 'loss': 2527.0488, 'global_step': 256000}
INFO:root:eval: {'average_loss': 2.5931072, 'loss': 2538.1719, 'global_step': 258500}
INFO:root:eval: {'average_loss': 2.5759203, 'loss': 2521.3489, 'global_step': 261000}
INFO:root:eval: {'average_loss': 2.5690928, 'loss': 2514.666, 'global_step': 263500}
INFO:root:eval: {'average_loss': 2.5647418, 'loss': 2510.4075, 'global_step': 266000}
INFO:root:eval: {'average_loss': 2.5749607, 'loss': 2520.4097, 'global_step': 268500}
INFO:root:eval: {'average_loss': 2.5559034, 'loss': 2501.756, 'global_step': 271000}
INFO:root:eval: {'average_loss': 2.553062, 'loss': 2498.9749, 'global_step': 273500}
INFO:root:eval: {'average_loss': 2.5515246, 'loss': 2497.4702, 'global_step': 276000}
INFO:root:eval: {'average_loss': 2.5481591, 'loss': 2494.176, 'global_step': 278500}
INFO:root:eval: {'average_loss': 2.5431647, 'loss': 2489.2874, 'global_step': 281000}
INFO:root:eval: {'average_loss': 2.544428, 'loss': 2490.524, 'global_step': 283500}
INFO:root:eval: {'average_loss': 2.5332885, 'loss': 2479.6204, 'global_step': 286000}
INFO:root:eval: {'average_loss': 2.5325422, 'loss': 2478.8896, 'global_step': 288500}
INFO:root:eval: {'average_loss': 2.5361433, 'loss': 2482.4146, 'global_step': 291000}
INFO:root:eval: {'average_loss': 2.5263975, 'loss': 2472.8752, 'global_step': 293500}
INFO:root:eval: {'average_loss': 2.520228, 'loss': 2466.8364, 'global_step': 296000}
INFO:root:eval: {'average_loss': 2.5240772, 'loss': 2470.6042, 'global_step': 298500}
INFO:root:eval: {'average_loss': 2.5144148, 'loss': 2461.1465, 'global_step': 301000}
INFO:root:eval: {'average_loss': 2.511098, 'loss': 2457.9, 'global_step': 303500}
INFO:root:eval: {'average_loss': 2.5126104, 'loss': 2459.3801, 'global_step': 306000}
INFO:root:eval: {'average_loss': 2.5060108, 'loss': 2452.9204, 'global_step': 308500}
INFO:root:eval: {'average_loss': 2.5194085, 'loss': 2466.0344, 'global_step': 311000}
INFO:root:eval: {'average_loss': 2.5153406, 'loss': 2462.0527, 'global_step': 313500}
INFO:root:eval: {'average_loss': 2.5017793, 'loss': 2448.7786, 'global_step': 316000}
INFO:root:eval: {'average_loss': 2.4961596, 'loss': 2443.278, 'global_step': 318500}
INFO:root:eval: {'average_loss': 2.4937787, 'loss': 2440.9475, 'global_step': 321000}
INFO:root:eval: {'average_loss': 2.504957, 'loss': 2451.889, 'global_step': 323500}
INFO:root:eval: {'average_loss': 2.4880886, 'loss': 2435.378, 'global_step': 326000}
INFO:root:eval: {'average_loss': 2.4831955, 'loss': 2430.5886, 'global_step': 328500}
INFO:root:eval: {'average_loss': 2.4833782, 'loss': 2430.7673, 'global_step': 331000}
INFO:root:eval: {'average_loss': 2.4824088, 'loss': 2429.8186, 'global_step': 333500}
INFO:root:eval: {'average_loss': 2.4808874, 'loss': 2428.3293, 'global_step': 336000}
INFO:root:eval: {'average_loss': 2.4851387, 'loss': 2432.4905, 'global_step': 338500}
INFO:root:eval: {'average_loss': 2.48534, 'loss': 2432.6877, 'global_step': 341000}
INFO:root:eval: {'average_loss': 2.4712658, 'loss': 2418.9114, 'global_step': 343500}
INFO:root:eval: {'average_loss': 2.4701483, 'loss': 2417.8176, 'global_step': 346000}
INFO:root:eval: {'average_loss': 2.4718184, 'loss': 2419.4526, 'global_step': 348500}
INFO:root:eval: {'average_loss': 2.4694765, 'loss': 2417.1602, 'global_step': 351000}
INFO:root:eval: {'average_loss': 2.4694438, 'loss': 2417.1282, 'global_step': 353500}
INFO:root:eval: {'average_loss': 2.467868, 'loss': 2415.5857, 'global_step': 356000}
INFO:root:eval: {'average_loss': 2.4664733, 'loss': 2414.2207, 'global_step': 358500}
INFO:root:eval: {'average_loss': 2.4634085, 'loss': 2411.2207, 'global_step': 361000}
INFO:root:eval: {'average_loss': 2.4629292, 'loss': 2410.7517, 'global_step': 363500}
INFO:root:eval: {'average_loss': 2.4540205, 'loss': 2402.0317, 'global_step': 366000}
INFO:root:eval: {'average_loss': 2.4567678, 'loss': 2404.7207, 'global_step': 368500}
INFO:root:eval: {'average_loss': 2.4515023, 'loss': 2399.567, 'global_step': 371000}
INFO:root:eval: {'average_loss': 2.4509785, 'loss': 2399.0542, 'global_step': 373500}
(118926, 10) (118926, 2)
(13214, 10) (13214, 2)
we are making progress: 0
we are making progress: 10
we are making progress: 20
we are making progress: 30
we are making progress: 40
we are making progress: 50
we are making progress: 60
we are making progress: 70
we are making progress: 80
we are making progress: 90
we are making progress: 100
we are making progress: 110
we are making progress: 120
we are making progress: 130
we are making progress: 140
we are making progress: 150
we are making progress: 160
we are making progress: 170
we are making progress: 180
we are making progress: 190
we are making progress: 200
we are making progress: 210
we are making progress: 220
we are making progress: 230
we are making progress: 240
we are making progress: 250
we are making progress: 260
we are making progress: 270
we are making progress: 280
we are making progress: 290
we are making progress: 300
we are making progress: 310
we are making progress: 320
we are making progress: 330
we are making progress: 340
we are making progress: 350
we are making progress: 360
we are making progress: 370
we are making progress: 380
we are making progress: 390
we are making progress: 400
we are making progress: 410
we are making progress: 420
we are making progress: 430
we are making progress: 440
we are making progress: 450
we are making progress: 460
we are making progress: 470
we are making progress: 480
we are making progress: 490
INFO:root:Tensorflow 1.8.0
INFO:root:Saving to /home/hornberger/MasterarbeitTobias/models/Aug13ev/weiz2
INFO:root:loading data from store
INFO:root:Train the DNN Regressor...

INFO:root:Progress: epoch0
INFO:root:eval: {'average_loss': 2.4580488, 'loss': 2405.9746, 'global_step': 376000}
INFO:root:Progress: epoch10
INFO:root:eval: {'average_loss': 2.486603, 'loss': 2433.9238, 'global_step': 378500}
INFO:root:Progress: epoch20
INFO:root:eval: {'average_loss': 2.4491265, 'loss': 2397.2412, 'global_step': 381000}
INFO:root:Progress: epoch30
INFO:root:eval: {'average_loss': 2.448439, 'loss': 2396.568, 'global_step': 383500}
INFO:root:Progress: epoch40
INFO:root:eval: {'average_loss': 2.4577715, 'loss': 2405.7034, 'global_step': 386000}
INFO:root:Progress: epoch50
INFO:root:eval: {'average_loss': 2.4496694, 'loss': 2397.7727, 'global_step': 388500}
INFO:root:Progress: epoch60
INFO:root:eval: {'average_loss': 2.4634695, 'loss': 2411.2805, 'global_step': 391000}
INFO:root:Progress: epoch70
INFO:root:eval: {'average_loss': 2.437179, 'loss': 2385.547, 'global_step': 393500}
INFO:root:Progress: epoch80
INFO:root:eval: {'average_loss': 2.4393816, 'loss': 2387.703, 'global_step': 396000}
INFO:root:Progress: epoch90
INFO:root:eval: {'average_loss': 2.4431384, 'loss': 2391.38, 'global_step': 398500}
INFO:root:Progress: epoch100
INFO:root:eval: {'average_loss': 2.4442677, 'loss': 2392.4854, 'global_step': 401000}
INFO:root:Progress: epoch110
INFO:root:eval: {'average_loss': 2.4338052, 'loss': 2382.2444, 'global_step': 403500}
INFO:root:Progress: epoch120
INFO:root:eval: {'average_loss': 2.4401176, 'loss': 2388.4233, 'global_step': 406000}
INFO:root:Progress: epoch130
INFO:root:eval: {'average_loss': 2.4325712, 'loss': 2381.0366, 'global_step': 408500}
INFO:root:Progress: epoch140
INFO:root:eval: {'average_loss': 2.4285393, 'loss': 2377.0903, 'global_step': 411000}
INFO:root:Progress: epoch150
INFO:root:eval: {'average_loss': 2.445328, 'loss': 2393.5232, 'global_step': 413500}
INFO:root:Progress: epoch160
INFO:root:eval: {'average_loss': 2.424594, 'loss': 2373.2285, 'global_step': 416000}
INFO:root:Progress: epoch170
INFO:root:eval: {'average_loss': 2.4278781, 'loss': 2376.443, 'global_step': 418500}
INFO:root:Progress: epoch180
INFO:root:eval: {'average_loss': 2.4250748, 'loss': 2373.699, 'global_step': 421000}
INFO:root:Progress: epoch190
INFO:root:eval: {'average_loss': 2.42602, 'loss': 2374.624, 'global_step': 423500}
INFO:root:Progress: epoch200
INFO:root:eval: {'average_loss': 2.4210718, 'loss': 2369.7808, 'global_step': 426000}
INFO:root:Progress: epoch210
INFO:root:eval: {'average_loss': 2.4297397, 'loss': 2378.2651, 'global_step': 428500}
INFO:root:Progress: epoch220
INFO:root:eval: {'average_loss': 2.4249845, 'loss': 2373.6108, 'global_step': 431000}
INFO:root:Progress: epoch230
INFO:root:eval: {'average_loss': 2.4269972, 'loss': 2375.5808, 'global_step': 433500}
INFO:root:Progress: epoch240
INFO:root:eval: {'average_loss': 2.418909, 'loss': 2367.664, 'global_step': 436000}
INFO:root:Progress: epoch250
INFO:root:eval: {'average_loss': 2.4311347, 'loss': 2379.6306, 'global_step': 438500}
INFO:root:Progress: epoch260
INFO:root:eval: {'average_loss': 2.4224825, 'loss': 2371.1619, 'global_step': 441000}
INFO:root:Progress: epoch270
INFO:root:eval: {'average_loss': 2.4192684, 'loss': 2368.0159, 'global_step': 443500}
INFO:root:Progress: epoch280
INFO:root:eval: {'average_loss': 2.4186287, 'loss': 2367.3896, 'global_step': 446000}
INFO:root:Progress: epoch290
INFO:root:eval: {'average_loss': 2.4208834, 'loss': 2369.5964, 'global_step': 448500}
INFO:root:Progress: epoch300
INFO:root:eval: {'average_loss': 2.4176757, 'loss': 2366.4568, 'global_step': 451000}
INFO:root:Progress: epoch310
INFO:root:eval: {'average_loss': 2.4372447, 'loss': 2385.6113, 'global_step': 453500}
INFO:root:Progress: epoch320
INFO:root:eval: {'average_loss': 2.413586, 'loss': 2362.4536, 'global_step': 456000}
INFO:root:Progress: epoch330
INFO:root:eval: {'average_loss': 2.4099405, 'loss': 2358.8855, 'global_step': 458500}
INFO:root:Progress: epoch340
INFO:root:eval: {'average_loss': 2.4083476, 'loss': 2357.3264, 'global_step': 461000}
INFO:root:Progress: epoch350
INFO:root:eval: {'average_loss': 2.4126253, 'loss': 2361.5134, 'global_step': 463500}
INFO:root:Progress: epoch360
INFO:root:eval: {'average_loss': 2.4262154, 'loss': 2374.8154, 'global_step': 466000}
INFO:root:Progress: epoch370
INFO:root:eval: {'average_loss': 2.4077902, 'loss': 2356.7808, 'global_step': 468500}
INFO:root:Progress: epoch380
INFO:root:eval: {'average_loss': 2.40209, 'loss': 2351.2012, 'global_step': 471000}
INFO:root:Progress: epoch390
INFO:root:eval: {'average_loss': 2.4007297, 'loss': 2349.8699, 'global_step': 473500}
INFO:root:Progress: epoch400
INFO:root:eval: {'average_loss': 2.4052413, 'loss': 2354.2856, 'global_step': 476000}
INFO:root:Progress: epoch410
INFO:root:eval: {'average_loss': 2.400959, 'loss': 2350.0942, 'global_step': 478500}
INFO:root:Progress: epoch420
INFO:root:eval: {'average_loss': 2.4035585, 'loss': 2352.6387, 'global_step': 481000}
INFO:root:Progress: epoch430
INFO:root:eval: {'average_loss': 2.3979404, 'loss': 2347.1396, 'global_step': 483500}
INFO:root:Progress: epoch440
INFO:root:eval: {'average_loss': 2.401254, 'loss': 2350.383, 'global_step': 486000}
INFO:root:Progress: epoch450
INFO:root:eval: {'average_loss': 2.39656, 'loss': 2345.7886, 'global_step': 488500}
INFO:root:Progress: epoch460
INFO:root:eval: {'average_loss': 2.4049115, 'loss': 2353.9631, 'global_step': 491000}
INFO:root:Progress: epoch470
INFO:root:eval: {'average_loss': 2.3990774, 'loss': 2348.2527, 'global_step': 493500}
INFO:root:Progress: epoch480
INFO:root:eval: {'average_loss': 2.4166358, 'loss': 2365.439, 'global_step': 496000}
INFO:root:Progress: epoch490
INFO:root:eval: {'average_loss': 2.4009008, 'loss': 2350.0374, 'global_step': 498500}
(118926, 10) (118926, 2)
(13214, 10) (13214, 2)
INFO:root:Tensorflow 1.8.0
INFO:root:Saving to /home/hornberger/MasterarbeitTobias/models/Aug13ev/weiz2
INFO:root:loading data from store
INFO:root:No training today, just prediction
INFO:root:Error on whole Test set:
MSE (tensorflow): 2.396048
INFO:root:Saving Image to file /home/hornberger/MasterarbeitTobias/images/weiz2_2018-08-15_10.08.36.png
(118926, 10) (118926, 2)
(13214, 10) (13214, 2)
           X_0     X_1     X_2     X_3   ...      Y_1    Y_2    Y_3     Y_4
120386  1909.0  1909.0  1909.0  1910.0   ...    788.0  867.0  946.0  1025.0

[1 rows x 10 columns]
        LabelX  LabelY
120386  1910.0  1104.0
predicted: 
[1909.66 1103.85]
time: 0.19s
MSE (tensorflow): 0.068869
pixelErrorX.mean: 0.010573786543125427
pixelErrorY.mean: 0.07597224745209863
pixelErrorTotal.mean: 1.362713966620352
        pixelErrorX   pixelErrorY  pixelErrorTotal
count  13214.000000  13214.000000     13214.000000
mean       0.010574      0.075972         1.362714
std        1.646422      1.440788         1.713280
min      -38.128906    -38.507202         0.011324
25%       -0.388329     -0.577179         0.604899
50%        0.053650      0.085388         0.987186
75%        0.527267      0.736115         1.565586
max       39.104614     63.366455        67.608445
INFO:root:Tensorflow 1.8.0
INFO:root:Saving to /home/hornberger/MasterarbeitTobias/models/Aug13ev/weiz2
INFO:root:loading data from store
INFO:root:No training today, just prediction
INFO:root:Error on whole Test set:
MSE (tensorflow): 2.396048
INFO:root:Saving Image to file /home/hornberger/MasterarbeitTobias/images/weiz2_2018-08-15_10.13.00.png
(118926, 10) (118926, 2)
(13214, 10) (13214, 2)
          X_0     X_1     X_2     X_3   ...       Y_1     Y_2     Y_3     Y_4
76626  1744.0  1744.0  1744.0  1744.0   ...    1312.0  1390.0  1467.0  1544.0

[1 rows x 10 columns]
       LabelX  LabelY
76626  1743.0  1622.0
predicted: 
[1744.34 1621.54]
time: 0.19s
MSE (tensorflow): 0.999351
pixelErrorX.mean: 0.010573786543125427
pixelErrorY.mean: 0.07597224745209863
pixelErrorTotal.mean: 1.362713966620352
        pixelErrorX   pixelErrorY  pixelErrorTotal
count  13214.000000  13214.000000     13214.000000
mean       0.010574      0.075972         1.362714
std        1.646422      1.440788         1.713280
min      -38.128906    -38.507202         0.011324
25%       -0.388329     -0.577179         0.604899
50%        0.053650      0.085388         0.987186
75%        0.527267      0.736115         1.565586
max       39.104614     63.366455        67.608445
