INFO:root:Tensorflow 1.8.0
INFO:root:time: 2018-09-10_11.51.37
INFO:root:Saving to /home/hornberger/MasterarbeitTobias/models/hyperParamTuning/weiz-5layers
INFO:root:/home/hornberger/MasterarbeitTobias/models/hyperParamTuning/weiz-5layers does not exist. Creating folder
INFO:root:loading data from store
INFO:root:Train: ((176706, 10), (176706, 2))
INFO:root:Test: ((9818, 10), (9818, 2))
INFO:root:Train the DNN Regressor...

INFO:root:Progress: epoch 0
INFO:root:eval: {'average_loss': 166.13144, 'loss': 163107.84, 'global_step': 500}
INFO:root:Progress: epoch 10
INFO:root:eval: {'average_loss': 31.327688, 'loss': 30757.525, 'global_step': 5500}
INFO:root:Progress: epoch 20
INFO:root:eval: {'average_loss': 24.487642, 'loss': 24041.967, 'global_step': 10500}
INFO:root:Progress: epoch 30
INFO:root:eval: {'average_loss': 16.629396, 'loss': 16326.74, 'global_step': 15500}
INFO:root:Progress: epoch 40
INFO:root:eval: {'average_loss': 2.9437418, 'loss': 2890.1655, 'global_step': 20500}
INFO:root:Progress: epoch 50
INFO:root:eval: {'average_loss': 5.3635683, 'loss': 5265.9517, 'global_step': 25500}
INFO:root:Progress: epoch 60
INFO:root:eval: {'average_loss': 4.221185, 'loss': 4144.36, 'global_step': 30500}
INFO:root:Progress: epoch 70
INFO:root:eval: {'average_loss': 4.869714, 'loss': 4781.085, 'global_step': 35500}
INFO:root:Progress: epoch 80
INFO:root:eval: {'average_loss': 1.6257981, 'loss': 1596.2086, 'global_step': 40500}
INFO:root:Progress: epoch 90
INFO:root:eval: {'average_loss': 18.132927, 'loss': 17802.908, 'global_step': 45500}
INFO:root:Progress: epoch 100
INFO:root:eval: {'average_loss': 4.4876976, 'loss': 4406.0215, 'global_step': 50500}
INFO:root:Progress: epoch 110
INFO:root:eval: {'average_loss': 1.9371651, 'loss': 1901.9088, 'global_step': 55500}
INFO:root:Progress: epoch 120
INFO:root:eval: {'average_loss': 2.0203347, 'loss': 1983.5647, 'global_step': 60500}
INFO:root:Progress: epoch 130
INFO:root:eval: {'average_loss': 1.5789034, 'loss': 1550.1674, 'global_step': 65500}
INFO:root:Progress: epoch 140
INFO:root:eval: {'average_loss': 1.5091523, 'loss': 1481.6858, 'global_step': 70500}
INFO:root:Progress: epoch 150
INFO:root:eval: {'average_loss': 5.9693213, 'loss': 5860.6797, 'global_step': 75500}
INFO:root:Progress: epoch 160
INFO:root:eval: {'average_loss': 7.6758304, 'loss': 7536.1304, 'global_step': 80500}
INFO:root:Progress: epoch 170
INFO:root:eval: {'average_loss': 5.5468173, 'loss': 5445.865, 'global_step': 85500}
INFO:root:Progress: epoch 180
INFO:root:eval: {'average_loss': 1.6672934, 'loss': 1636.9486, 'global_step': 90500}
INFO:root:Progress: epoch 190
INFO:root:eval: {'average_loss': 1.4595422, 'loss': 1432.9785, 'global_step': 95500}
INFO:root:Progress: epoch 200
INFO:root:eval: {'average_loss': 5.378265, 'loss': 5280.3804, 'global_step': 100500}
INFO:root:Progress: epoch 210
INFO:root:eval: {'average_loss': 1.2887572, 'loss': 1265.3019, 'global_step': 105500}
INFO:root:Progress: epoch 220
INFO:root:eval: {'average_loss': 3.2077477, 'loss': 3149.3667, 'global_step': 110500}
INFO:root:Progress: epoch 230
INFO:root:eval: {'average_loss': 3.3842075, 'loss': 3322.6147, 'global_step': 115500}
INFO:root:Progress: epoch 240
INFO:root:eval: {'average_loss': 2.3062449, 'loss': 2264.2712, 'global_step': 120500}
INFO:root:Progress: epoch 250
INFO:root:eval: {'average_loss': 6.2942376, 'loss': 6179.6826, 'global_step': 125500}
INFO:root:Progress: epoch 260
INFO:root:eval: {'average_loss': 2.365577, 'loss': 2322.5234, 'global_step': 130500}
INFO:root:Progress: epoch 270
INFO:root:eval: {'average_loss': 2.6275108, 'loss': 2579.69, 'global_step': 135500}
INFO:root:Progress: epoch 280
INFO:root:eval: {'average_loss': 2.0125823, 'loss': 1975.9534, 'global_step': 140500}
INFO:root:Progress: epoch 290
INFO:root:eval: {'average_loss': 1.8304931, 'loss': 1797.1781, 'global_step': 145500}
INFO:root:Progress: epoch 300
INFO:root:eval: {'average_loss': 1.5616944, 'loss': 1533.2716, 'global_step': 150500}
INFO:root:Progress: epoch 310
INFO:root:eval: {'average_loss': 1.3549535, 'loss': 1330.2933, 'global_step': 155500}
INFO:root:Progress: epoch 320
INFO:root:eval: {'average_loss': 3.9987888, 'loss': 3926.011, 'global_step': 160500}
INFO:root:Progress: epoch 330
INFO:root:eval: {'average_loss': 3.5413594, 'loss': 3476.9067, 'global_step': 165500}
INFO:root:Progress: epoch 340
INFO:root:eval: {'average_loss': 1.2559642, 'loss': 1233.1057, 'global_step': 170500}
INFO:root:Progress: epoch 350
INFO:root:eval: {'average_loss': 2.136387, 'loss': 2097.505, 'global_step': 175500}
INFO:root:Progress: epoch 360
INFO:root:eval: {'average_loss': 1.8914665, 'loss': 1857.0417, 'global_step': 180500}
INFO:root:Progress: epoch 370
INFO:root:eval: {'average_loss': 1.5911534, 'loss': 1562.1943, 'global_step': 185500}
INFO:root:Progress: epoch 380
INFO:root:eval: {'average_loss': 4.378697, 'loss': 4299.005, 'global_step': 190500}
INFO:root:Progress: epoch 390
INFO:root:eval: {'average_loss': 1.6859806, 'loss': 1655.2957, 'global_step': 195500}
INFO:root:Progress: epoch 400
INFO:root:eval: {'average_loss': 1.6871284, 'loss': 1656.4226, 'global_step': 200500}
INFO:root:Progress: epoch 410
INFO:root:eval: {'average_loss': 3.9156146, 'loss': 3844.3503, 'global_step': 205500}
INFO:root:Progress: epoch 420
INFO:root:eval: {'average_loss': 1.2927825, 'loss': 1269.2539, 'global_step': 210500}
INFO:root:Progress: epoch 430
INFO:root:eval: {'average_loss': 1.4694246, 'loss': 1442.681, 'global_step': 215500}
INFO:root:Progress: epoch 440
INFO:root:eval: {'average_loss': 1.6023481, 'loss': 1573.1853, 'global_step': 220500}
INFO:root:Progress: epoch 450
INFO:root:eval: {'average_loss': 5.5599246, 'loss': 5458.734, 'global_step': 225500}
INFO:root:Progress: epoch 460
INFO:root:eval: {'average_loss': 1.4765483, 'loss': 1449.675, 'global_step': 230500}
INFO:root:Progress: epoch 470
INFO:root:eval: {'average_loss': 1.5298498, 'loss': 1502.0065, 'global_step': 235500}
INFO:root:Progress: epoch 480
INFO:root:eval: {'average_loss': 2.5406373, 'loss': 2494.3977, 'global_step': 240500}
INFO:root:Progress: epoch 490
INFO:root:eval: {'average_loss': 1.4360973, 'loss': 1409.9603, 'global_step': 245500}
INFO:root:Training completed. final average loss: 2.701, best average loss during training: 1.256
INFO:root:Tensorflow 1.8.0
INFO:root:time: 2018-09-10_12.35.50
INFO:root:Saving to /home/hornberger/MasterarbeitTobias/models/hyperParamTuning/weiz-5layers
INFO:root:loading data from store
INFO:root:Train: ((176706, 10), (176706, 2))
INFO:root:Test: ((9818, 10), (9818, 2))
INFO:root:Train the DNN Regressor...

INFO:root:Progress: epoch 0
INFO:root:eval: {'average_loss': 1.8008296, 'loss': 1768.0544, 'global_step': 250500}
INFO:root:Progress: epoch 10
INFO:root:eval: {'average_loss': 1.5548611, 'loss': 1526.5626, 'global_step': 255500}
INFO:root:Progress: epoch 20
INFO:root:eval: {'average_loss': 6.397951, 'loss': 6281.5083, 'global_step': 260500}
INFO:root:Progress: epoch 30
INFO:root:eval: {'average_loss': 1.1617526, 'loss': 1140.6086, 'global_step': 265500}
INFO:root:Progress: epoch 40
INFO:root:eval: {'average_loss': 1.7430557, 'loss': 1711.332, 'global_step': 270500}
INFO:root:Progress: epoch 50
INFO:root:eval: {'average_loss': 1.3886478, 'loss': 1363.3744, 'global_step': 275500}
INFO:root:Progress: epoch 60
INFO:root:eval: {'average_loss': 2.2994487, 'loss': 2257.5989, 'global_step': 280500}
INFO:root:Progress: epoch 70
INFO:root:eval: {'average_loss': 4.997471, 'loss': 4906.5166, 'global_step': 285500}
INFO:root:Progress: epoch 80
INFO:root:eval: {'average_loss': 3.2117002, 'loss': 3153.2473, 'global_step': 290500}
INFO:root:Progress: epoch 90
INFO:root:eval: {'average_loss': 1.9572803, 'loss': 1921.6578, 'global_step': 295500}
INFO:root:Progress: epoch 100
INFO:root:eval: {'average_loss': 3.1781683, 'loss': 3120.3257, 'global_step': 300500}
INFO:root:Progress: epoch 110
INFO:root:eval: {'average_loss': 2.3129818, 'loss': 2270.8855, 'global_step': 305500}
INFO:root:Progress: epoch 120
INFO:root:eval: {'average_loss': 2.0979438, 'loss': 2059.7612, 'global_step': 310500}
INFO:root:Progress: epoch 130
INFO:root:eval: {'average_loss': 1.7685859, 'loss': 1736.3977, 'global_step': 315500}
INFO:root:Progress: epoch 140
INFO:root:eval: {'average_loss': 3.9088974, 'loss': 3837.7554, 'global_step': 320500}
INFO:root:Progress: epoch 150
INFO:root:eval: {'average_loss': 1.1304092, 'loss': 1109.8357, 'global_step': 325500}
INFO:root:Progress: epoch 160
INFO:root:eval: {'average_loss': 3.6687202, 'loss': 3601.9497, 'global_step': 330500}
INFO:root:Progress: epoch 170
INFO:root:eval: {'average_loss': 3.4716742, 'loss': 3408.4897, 'global_step': 335500}
INFO:root:Progress: epoch 180
INFO:root:eval: {'average_loss': 4.306964, 'loss': 4228.577, 'global_step': 340500}
INFO:root:Progress: epoch 190
INFO:root:eval: {'average_loss': 1.8985368, 'loss': 1863.9834, 'global_step': 345500}
INFO:root:Progress: epoch 200
INFO:root:eval: {'average_loss': 1.8968432, 'loss': 1862.3207, 'global_step': 350500}
INFO:root:Progress: epoch 210
INFO:root:eval: {'average_loss': 8.780397, 'loss': 8620.595, 'global_step': 355500}
INFO:root:Progress: epoch 220
INFO:root:eval: {'average_loss': 1.6583568, 'loss': 1628.1747, 'global_step': 360500}
INFO:root:Progress: epoch 230
INFO:root:eval: {'average_loss': 3.6887162, 'loss': 3621.5815, 'global_step': 365500}
INFO:root:Progress: epoch 240
INFO:root:eval: {'average_loss': 2.1438353, 'loss': 2104.8176, 'global_step': 370500}
INFO:root:Progress: epoch 250
INFO:root:eval: {'average_loss': 1.4491167, 'loss': 1422.7428, 'global_step': 375500}
INFO:root:Progress: epoch 260
INFO:root:eval: {'average_loss': 1.2154067, 'loss': 1193.2863, 'global_step': 380500}
INFO:root:Progress: epoch 270
INFO:root:eval: {'average_loss': 1.422389, 'loss': 1396.5016, 'global_step': 385500}
INFO:root:Progress: epoch 280
INFO:root:eval: {'average_loss': 2.3809655, 'loss': 2337.6318, 'global_step': 390500}
INFO:root:Progress: epoch 290
INFO:root:eval: {'average_loss': 2.8506553, 'loss': 2798.7734, 'global_step': 395500}
INFO:root:Progress: epoch 300
INFO:root:eval: {'average_loss': 1.3468112, 'loss': 1322.2992, 'global_step': 400500}
INFO:root:Progress: epoch 310
INFO:root:eval: {'average_loss': 1.4131329, 'loss': 1387.4138, 'global_step': 405500}
INFO:root:Progress: epoch 320
INFO:root:eval: {'average_loss': 2.6600482, 'loss': 2611.6353, 'global_step': 410500}
INFO:root:Progress: epoch 330
INFO:root:eval: {'average_loss': 2.6610196, 'loss': 2612.589, 'global_step': 415500}
INFO:root:Progress: epoch 340
INFO:root:eval: {'average_loss': 3.3718739, 'loss': 3310.5059, 'global_step': 420500}
INFO:root:Progress: epoch 350
INFO:root:eval: {'average_loss': 2.9712873, 'loss': 2917.2097, 'global_step': 425500}
INFO:root:Progress: epoch 360
INFO:root:eval: {'average_loss': 2.0999734, 'loss': 2061.754, 'global_step': 430500}
INFO:root:Progress: epoch 370
INFO:root:eval: {'average_loss': 3.229082, 'loss': 3170.313, 'global_step': 435500}
INFO:root:Progress: epoch 380
INFO:root:eval: {'average_loss': 2.933055, 'loss': 2879.6733, 'global_step': 440500}
INFO:root:Progress: epoch 390
INFO:root:eval: {'average_loss': 2.7640293, 'loss': 2713.724, 'global_step': 445500}
INFO:root:Progress: epoch 400
INFO:root:eval: {'average_loss': 1.2128005, 'loss': 1190.7275, 'global_step': 450500}
INFO:root:Progress: epoch 410
INFO:root:eval: {'average_loss': 2.0023093, 'loss': 1965.8672, 'global_step': 455500}
INFO:root:Progress: epoch 420
INFO:root:eval: {'average_loss': 3.1010597, 'loss': 3044.6204, 'global_step': 460500}
INFO:root:Progress: epoch 430
INFO:root:eval: {'average_loss': 1.4472314, 'loss': 1420.8918, 'global_step': 465500}
INFO:root:Progress: epoch 440
INFO:root:eval: {'average_loss': 2.2465346, 'loss': 2205.6477, 'global_step': 470500}
INFO:root:Progress: epoch 450
INFO:root:eval: {'average_loss': 2.0891883, 'loss': 2051.165, 'global_step': 475500}
INFO:root:Progress: epoch 460
INFO:root:eval: {'average_loss': 2.482988, 'loss': 2437.7979, 'global_step': 480500}
INFO:root:Progress: epoch 470
INFO:root:eval: {'average_loss': 1.9605011, 'loss': 1924.82, 'global_step': 485500}
INFO:root:Progress: epoch 480
INFO:root:eval: {'average_loss': 1.2542638, 'loss': 1231.4362, 'global_step': 490500}
INFO:root:Progress: epoch 490
INFO:root:eval: {'average_loss': 2.276149, 'loss': 2234.7231, 'global_step': 495500}
INFO:root:Training completed. final average loss: 4.180, best average loss during training: 1.130
