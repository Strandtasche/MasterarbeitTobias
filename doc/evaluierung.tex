\chapter{Evaluation}
\label{cap:Eval}

Im vorhergegangenen Kapitel wurde die Implementierung der neuronalen Netze beschrieben.
Nun wird in diesem Kapitel betrachtet, wie gut die Ergebnisse sind, die von diesen Netzen geliefert werden.
Dazu wird zunächst beschrieben, auf was für einem System das Training und die Evaluation durchgeführt wurde.
Es werden mehrere, bereits aus dem Stand der Technik bekannte Modelle beschrieben, die dann mit den Ergebnissen der neuronalen Netze 
verglichen werden.
Anschließend werden diese Ergebnisse diskutiert.
% \todo[inline]{Im vorhergegangenen Kapitel wurde beschrieben, [wie die Netze designed wurde]
% Jetzt bewerten wie gut sie das eigentlich mache.}

% \section{System}

Alle in dieser Arbeit vorgestellten Netze wurden auf einem Ubuntu 18.04 Linux System trainiert und evaluiert.
Dieses verfügt über einen Intel i7-7700k CPU mit \SI{4.20}{\giga\hertz}, \SI{32}{\giga\byte}~RAM und eine NVIDIA GeForce 1080Ti Grafikkarte mit \SI{11}{\giga\byte}~GDDR5X. 

% \todo[inline]{muss da noch irgendwie mehr dazu? Ansonsten nicht als eigener Abschnitt sondern an den Header text dran?}

\section{Vergleichsmodelle}

% \color{blue}
% Notation und Definition bei allen diesen Modellen nach Florian's Diss \cite{Pfaff2018}, mit Ausnahme von Average Acceleration.
% Sei \(x(t)\) die Position des Partikels entlang der Bewegungsrichtung in Abhängigkeit von der Zeit
% (continuous-time equation).
% Sei \( y(t)\) die Position des Partikels orthogonal zur Bewegungsrichtung in Abhängigkeit von der Zeit.
% \(t^{\text{Last}}\) ist der Zeitpunkt der Beobachtung des letzten Features.
% % Sei \(\Delta t =  t - t^{\text{Last}}\).

% Vergleich über Boxplots: Balken: 25\%-Quantil bis 75\%-Quantil.
% Roter Balken ist der Median. Der obere und der untere Whisker 
% gehen bis zum höchsten bzw. niedrigsten Wert, der nicht mehr als 2.7 Standardabweichungen vom Median abweicht
% Die Outlier werden nicht abgebildet.

% \color{black}

In diesem Abschnitt sollen einige der existierenden Modelle detaillierter beschrieben werden, mit denen die Ergebnisse der neuronalen Netze nun verglichen werden.
Diese Modelle wurden schon in Abschnitt~\ref{cap:relWork} erwähnt, dort aber ohne die Berechnung zu erklären.
Mit Ausnahme des \textit{Average Acceleration} Modells stammen sie alle aus \cite{Pfaff2018} und sowohl Definition als auch Notation wurden von dort übernommen.
Dabei seien \(\mathsf{x}\) die Achse entlang der Bewegungsrichtung des Förderbands und \(\mathsf{y}\) die Achse orthogonal zur Bewegungsrichtung des Förderbands.
Zeitdiskrete Messungen entlang der einzelnen Achsen werden als \(\mathsf{x}_t\) beziehungsweise \(\mathsf{y}_t\) dargestellt.
Die daraus rekonstruierten zeitkontinuierlichen Positionsgleichungen werden als \(\mathsf{x}(t)\) beziehungsweise \(\mathsf{y}(t)\) bezeichnet.
Sei \(t^{\text{Last}}\) der Zeitpunkt der Beobachtung des aktuellsten Features und \(\mathsf{x}^{\text{Last}}\) und \(\mathsf{y}^{\text{Last}}\) die dazugehörigen Positionen entlang der beiden Achsen.
Sei \(\mathsf{x}^{\text{PredTo}}\) die Position des Druckluftdüsenarrays entlang der \(\mathsf{x}\)-Achse.
Der Zeitpunkt, an dem ein Partikel das Druckluftdüsenarray passiert, wird als \(t^{\text{Pred}}\) bezeichnet.
Sei \(\mathsf{y}^{\text{Pred}} = \mathsf{y}(t^{\text{Pred}})\) die Position entlang der \(\mathsf{y}\)-Achse, an dem der Partikel den Druckluftdüsenarray passiert.
Die Zeit, die der Partikel noch benötigt um das Druckluftdüsenarray zu erreichen \(\Delta t = t^{\text{Pred}} - t^{\text{Last}} \) und die Position an der er es passiert \(\mathsf{y}^{\text{Pred}}\) sind die Labels der einzelnen Feature-Label-Paare für das Separator-Netz.
\(\mathsf{x}(t^{\text{Last}} + 1)\) und \(\mathsf{y}(t^{\text{Last}} + 1)\), also jeweils einen diskreten Zeitschritt in die Zukunft, sind die Labels der Feature-Label-Paare für das NextStep-Netz.
Die verschiedenen Modelle können nun ebenso wie die Ergebnisse der verschiedenen Netze bewertet werden, 
indem man die Abweichung zwischen dem Ergebnis in dem Modell und der Ground Truth in den Feature-Label-Paaren bestimmt.
% \todo[inline]{Das formatting hier ist total schlecht - überlegen wie ich das gut machen kann.}


Für Modelle, die unabhängig von der Beschleunigung der Teilchen sind, ist der Zustandsvektor als 
% 
\begin{equation} \label{eq:definitionCV}
    \vx(t) = 
    \begin{bmatrix}
        \mathsf{x}(t) \\
        \dot{\mathsf{x}}(t) \\
        \mathsf{y}(t) \\
        \dot{\mathsf{y}}(t)
       \end{bmatrix} 
\end{equation}
% 
definiert.
Für Modelle, die die Beschleunigung der Teilchen mit einbeziehen, ist der Zustandsvektor folgendermaßen definiert:
% 
\begin{equation} \label{eq:definitionCA}
    \vx(t) = 
    \begin{bmatrix}
        \mathsf{x}(t) \\
        \dot{\mathsf{x}}(t) \\
        \ddot{\mathsf{x}}(t) \\
        \mathsf{y}(t) \\
        \dot{\mathsf{y}}(t) \\
        \ddot{\mathsf{y}}(t)
       \end{bmatrix} \, .
\end{equation}
% % 
% \todo[inline]{Irgendwo irgendwas dazu sagen, wie es mutmaßlich wirklich ist?
% Geschwindigkeit Förderband ist eine obere Grenze - bis dahin beschleunigen, dann konstante Geschwindigkeit.
% Wie schnell diese Geschwindigkeit erreicht wird hängt von der Art des Schüttguts ab.
% Je länger das Band desto mehr Zeit hat das Schüttgut sich an die Geschwindigkeit anzupassen.}

\paragraph{Constant Velocity Modell}

Das Constant Velocity (CV) Modell arbeitet unter der Annahme, dass sich Partikel, 
abgesehen von einem Rauschterm, mit einer konstanten Geschwindigkeit bewegen.
Es kann mittels folgender Differenzialgleichung dargestellt werden.

\begin{equation*} \label{eq:CVDiff}
    \dot{\vx}(t) = \mat{A}\vx(t), \quad \mat{A} = 
    \begin{bmatrix}
        0 & 1 & 0 & 0 \\
        0 & 0 & 0 & 0 \\
        0 & 0 & 0 & 1\\
        0 & 0 & 0 & 0
    \end{bmatrix} \, .
\end{equation*}

Daraus folgen die Positionsgleichungen 
\begin{equation*}
    \mathsf{x}(t) = \mathsf{x}^{\text{Last}} + (t - t^{\text{Last}})\dot{\mathsf{x}}^{\text{Last}} \: ,
\end{equation*}
\begin{equation*}
    \mathsf{y}(t) = \mathsf{y}^{\text{Last}} + (t - t^{\text{Last}})\dot{\mathsf{y}}^{\text{Last}}
\end{equation*}
% 
entlang der einzelnen Achsen.
Für das NextStep-Szenario ergibt sich die Prädiktionen mittels des CV Modells also aus
\begin{equation*}
    \mathsf{x}(t\hitext{Last}+1) = \mathsf{x}^{\text{Last}} + \dot{\mathsf{x}}^{\text{Last}} \: ,
\end{equation*}
\begin{equation}
    \label{eq:cvyp}
    \mathsf{y}(t\hitext{Last}+1) = \mathsf{y}^{\text{Last}} + \dot{\mathsf{y}}^{\text{Last}} \: .
\end{equation}

Für das Separator-Szenario wird die Gleichung 
% 
\begin{equation*}
    \mathsf{x}^{\text{PredTo}} = \mathsf{x}^{\text{Last}} + (t - t^{\text{Last}})\dot{\mathsf{x}}^{\text{Last}}
\end{equation*}
% 
nach \(t\) gelöst um  \(t^{\text{Pred}}\) und damit \(\Delta t\) zu erhalten.
Durch das Einsetzen von \(t^{\text{Pred}}\) in Gleichung~\eqref{eq:cvyp} ergibt sich \(\mathsf{y}^{\text{Pred}}\).

\paragraph{Constant Acceleration Modell}

Im Constant Acceleration (CA) Modell wird davon ausgegangen, dass das Teilchen mit einer konstanten Beschleunigung schneller wird.
Es kann mittels folgender Differenzialgleichung dargestellt werden.
% 
\begin{align*} \label{eq:CADiff}
    \dot{\vx}(t) = \mat{A}\vx(t), \quad \mat{A} = 
    \begin{bmatrix}
        \mat{A}_x & \boldsymbol{0} \\
        \boldsymbol{0} & \mat{A}_y
    \end{bmatrix} 
    , \quad
    \mat{A}_x = \mat{A}_y = 
    \begin{bmatrix}
        0 & 1 & 0 \\
        0 & 0 & 1 \\
        0 & 0 & 0
    \end{bmatrix} \, .
\end{align*}

Analog zum Constant Velocity Modell können daraus die Positionsgleichungen 
% 
\begin{equation} 
    \mathsf{x}(t) = \mathsf{x}^{\text{Last}} + (t - t^{\text{Last}})\dot{\mathsf{x}}^{\text{Last}} + \frac{1}{2} (t - t^{\text{Last}})^2 \: \ddot{\mathsf{x}}^{\text{Last}} \: , \label{eq:CAX}
\end{equation}
\begin{equation} 
    \mathsf{y}(t) = \mathsf{y}^{\text{Last}} + (t - t^{\text{Last}})\dot{\mathsf{y}}^{\text{Last}}
    + \frac{1}{2} (t - t^{\text{Last}})^2 \: \ddot{\mathsf{y}}^{\text{Last}} \label{eq:CAY}
\end{equation}
% 
abgeleitet werden.
Nun wird wie beim Constant Velocity Modell vorgegangen.
Im NextStep-Fall werden die Gleichungen~\eqref{eq:CAX} und~\eqref{eq:CAY} für \(t = t\hitext{Last} + 1\) gelöst.
Im Separator-Fall wird \(\Delta t = t^{\text{Pred}} - t^{\text{Last}} \) aus
\begin{equation*} 
    \mathsf{x}\hitext{Pred} = \mathsf{x}^{\text{Last}} + (t - t^{\text{Last}})\dot{\mathsf{x}}^{\text{Last}} 
    + \frac{1}{2} (t - t^{\text{Last}})^2 \: \ddot{\mathsf{x}}^{\text{Last}} \: , \label{eq:CAX2}
\end{equation*}
errechnet und durch Einsetzen in Gleichung~\eqref{eq:CAY} \(\mathsf{y}^{\text{Pred}}\) bestimmt.


\paragraph{Bias-Corrected Constant Velocity Modell}

In \cite{Pfaff2018} wurden weitere szenariospezifische Bewegungsmodelle beschrieben, die insbesondere die Qualität der zeitlichen Prädiktion für den Separator-Fall verbessern.
Das erste von diesen Modellen, das hier zum Vergleich mit den Ergebnissen der neuronalen Netze betrachtet werden soll, ist eine Verbesserung des Constant Velocity Modells und wird als Bias-Corrected Constant Velocity (CVBC) Modell bezeichnet.
Durch das Bestimmen des Bias bezüglich der Ankunftszeit der Partikel am Druckluftdüsenarray in den Trainingsdaten und das Abziehen desselben von der Prädiktion der Testdaten kann die Qualität dieser Prädiktion verbessert werden.
Dieser neue Wert kann nun für die Ortsprädiktion benutzt werden und diese tendenziell verbessern.
Damit ergibt sich für die vorhergesagte Ankunftszeit
% 
\begin{equation*}
    t\hitext{Pred,CVBC} = t\hitext{Pred,CV} - t\hitext{Bias} \, ,
\end{equation*}
% 
wobei \(t\hitext{Bias}\) den Bias bezüglich der Ankunftszeit auf den Trainingsdaten bezeichnet.
Analog zum unveränderten Constant Velocity Modell erhält man nun durch das Einsetzen von \(t^{\text{Pred,CVBC}}\) in \eqref{eq:cvyp} erneut \(\mathsf{y}^{\text{Pred,CVBC}}\).
Die Verbesserung der prädizierten Zeit führt tendenziell ebenfalls zu einer Verbesserung des prädizierten Orts.


\paragraph{Average Acceleration Modell}

% \color{blue}
% Für alle Elemente des Trainingssets: Bestimme die Beschleunigungen.
% Sei \(\ddot{x}\hitext{Median}\) der Median von all diesen Beschleunigungen.
% Benutze ihn als Beschleunigung wie im CA Modell

% (Basicly CV Modell + eine Beschleunigung basierend auf den Trainingsdaten)

% \todo[inline]{überhaupt erwähnen? Er ist way better als er irgendein right hat}
% \color{black}

Das Average Acceleration (AA) Modell ist eine Erweiterung des CVBC-Modells.
Anstatt die durchschnittliche Abweichung der prädizierten Zeit in den Trainingsdaten auf die prädizierte Zeit zu addieren, wird angenommen, 
dass diese Abweichung aus einer nicht betrachteten Beschleunigung resultiert.
Diese Beschleunigung wird mutmaßlich vom Band verursacht werden und alle Partikel ortsunabhängig mehr oder weniger ähnlich betreffen.
Deshalb wird die Beschleunigung des Partikels in allen Feature-Label-Paaren des Trainingssets bestimmt
und von diesen der Median \(\ddot{ \mathsf{x}}^{\text{Median}}\) gewählt als eine einheitliche Beschleunigung, die zum CV Modell hinzugefügt wird.
Es folgt die Positionsgleichung
\begin{equation*}
    \mathsf{x}(t) =  \mathsf{x}^{\text{Last}} + (t - t^{\text{Last}}) \: \dot{ \mathsf{x}}^{\text{Last}} 
    + \frac{1}{2} (t - t^{\text{Last}})^2 \: \ddot{ \mathsf{x}}^{\text{Median}} \: ,
\end{equation*}
% 
die nach \(t\) für \(\mathsf{x}(t) =  \mathsf{x}^{\text{PredTo}}\) gelöst wird.


\paragraph{Identical Acceleration Modell}

% \color{blue}
% Upgrade zu CVBC: Correction Term, der den die Letzte Position des Partikels einbezieht.\\
% Annahme: Abweichungen bezüglich dem Zeit Label wird von einer zusätzlichen Beschleunigung verursacht.
% \color{black}

Das Identical Acceleration (IA) Modell ist ebenfalls eine Verbesserung des CVBC-Modells. 
Bei diesem werden die Korrekturterme, die als Beschleunigung auf die Positionsgleichungen addiert werden, nicht unabhängig von der letzten Position des Partikels bestimmt, sondern beziehen diese mit ein.
Wie oben wird hierbei die Annahme getroffen, dass die zusätzliche Beschleunigung, die für die zeitliche Abweichung sorgt, für alle Partikel ungefähr gleich ist.
Die Bestimmung dieser Korrekturterme ist jedoch unterschiedlich.
Für die Feature-Label-Paare des Trainingssets hat man man Zugang zu der Ground Truth, wann die Partikel das Druckluftdüsenarray passieren.

Dementsprechen wird für jedes Partikel \(i\) aus dem Trainingsset die Gleichung
% 
\begin{equation*}
    \mathsf{x}\hitext{PredTo} =  \mathsf{x}\hitext{Last,\(i\)} + (t\hitext{GT, \(i\)} - t\hitext{Last,\(i\)}) 
    \: \dot{ \mathsf{x}}\hitext{Last, \(i\)}
    + \frac{1}{2}(t\hitext{GT,\(i\)} - t\hitext{Last,\(i\)})^2 \: \ddot{ \mathsf{x}}\hitext{Optimal,\(i\)}
\end{equation*}
% 
gelöst, um herauszufinden, mit welcher zusätzlichen Beschleunigung \(\ddot{ \mathsf{x}}\hitext{Optimal,\(i\)}\) es optimal die Zeit,
die es noch braucht, vorhersagen würde.
Nun sei \(\ddot{ \mathsf{x}}\hitext{Avg}\) der Durchschnitt von allen \(\ddot{ \mathsf{x}}\hitext{Optimal,\(i\)}\).
Für die Partikel des Testsets werden die Zeit und der Ort des Passierens des Druckluftdüsenarrays nun basierend auf deren 
beobachteter Geschwindigkeiten \(\dot{ \mathsf{x}}^{\text{Last}}\) und der errechneten Beschleunigungen \(\ddot{ \mathsf{x}}\hitext{Avg}\) berechnet.
Die Zeitprädiktion \(t\hitext{Pred}\) wird, bestimmt indem wir
% 
\begin{equation*}
    \mathsf{x}(t) =  \mathsf{x}^{\text{Last}} + (t - t^{\text{Last}}) \: \dot{ \mathsf{x}}^{\text{Last}} 
    + \frac{1}{2} (t - t^{\text{Last}})^2 \: \ddot{ \mathsf{x}}\hitext{Avg}
\end{equation*}
% 
nach \(t\) lösen.

In \cite{Pfaff2018} werden zusätzlich zu den hier aufgeführten Modellen noch zwei Modelle vorgestellt, die sich speziell mit der Prädiktion der Orthogonalbewegung beschäftigen.
Im Rahmen dieser Arbeit wurden diese nicht berücksichtigt und sich stattdessen auf die Prädiktion des Zeitkomponente konzentriert.


% \todo{fertig machen}

\section{Next Step}

% \color{blue}
% Netz Variante 1: den nächsten Schritt vorhersagen
% \(\Delta t \) ist immer 1.


% Für Nextstep gesucht: \( \mathsf{x}(t^{\text{Last}} + 1)\)

% \todo[inline]{Latex Tabelle des pandas Dataframe mit den Spalten GroundtruthX, GroundtruthY, 
% NNPrädiktionX, NNPrädiktion, CV\_X, CV\_Y, CA\_X, CA\_Y}
% \color{black}

In dieser Sektion sollen die Ergebnisse der NextStep-Netze in verschiedenen Szenarien betrachtet werden.
Der Vergleich zwischen den Ergebnissen der unterschiedlichen Modelle wird mittels sogenannter Boxplots visualisiert.
Die fünf relevanten Charakteristiken, die in einem Boxplot dargestellt werden sind 
der Median, das untere und obere Quartil sowie zwei sogenannte "Antennen" oder auch "Whisker", die die Positionen der äußersten Datenpunkte innerhalb des 1.5-fachen Interquartilsabstands beschreiben.
Die Position des Medians wird durch eine rote Linie verdeutlicht.
Die namensgebende Box ist zwischen dem unteren und dem oberen Quartil aufgespannt.
Für die Darstellung in dieser Arbeit wurde darauf verzichtet Ausreißer außerhalb der Antennen abzubilden.
Als Evaluationskriterium für die NextStep-Netze wurde die Euklidische Distanz zwischen der Prädiktion des Modell und der Ground Truth gewählt.
Der Gesamtfehler \(\varepsilon\hitext{Total} \) ist also durch 
% 
\begin{align*}
    \mathsf{x}\hitext{Err} &=  \mathsf{x}\hitext{Pred} -  \mathsf{x}\hitext{GT} \: ,\\
    \mathsf{y}\hitext{Err} &=  \mathsf{y}\hitext{Pred} -  \mathsf{y}\hitext{GT} \: ,\\
    \varepsilon\hitext{Total} &= \sqrt{ \mathsf{x}\hitext{Err}^2 +  \mathsf{y}\hitext{Err}^2}
\end{align*}

definiert. Verglichen wird das NextStep-Netz mit einem Constant Velocity Modell und einen Constant Acceleration Modell, jeweils ohne Berücksichtigung von Rauschen. 

% Die im Rahmen dieser Arbeit trainierten neuronalen Netze haben in allen untersuchten Szenarien bessere Ergebnisse als die beiden Vergleichsmodelle geliefert.
% \todo{kann man das bei den Simulierten Zylindern so sagen?}
Repräsentativ für ihre jeweiligen Szenariokategorien sind in Abbildung~\ref{subfig:RealSpheresBoxplot} die Boxplots für die selbst aufgenommenen Kugeln auf dem Förderband,
und in Abbildung~\ref{subfig:SimSpheresBoxplot} die Boxplots für die mittels DEM simulierten Kugeln zu sehen.
In beiden Fällen sind die Ergebnisse des neuronalen Netzes besser als die der Vergleichsmodelle.
Sowohl der Median als auch die Quartile sind für die Ergebnisse des neuronalen Netzes geringer.
Die durchschnittliche Abweichung der Ergebnisse ist kleiner und weniger weit gestreut als die der beiden Vergleichsmodelle.
Es ist auffällig, dass bei den simulierten Daten das CA-Modell besser als das CV-Modell ist, während es auf den Realdaten umgekehrt ist.
Das könnte auf die höhere Bandgeschwindigkeit bei der Simulation zurückzuführen sein. 
In Abbildung~\ref{fig:RealSpheresHistogram} sieht man das Fehlerhistogramm, das zu Abbildung~\ref{subfig:RealSpheresBoxplot} gehört.
Die Boxplots von den hier vorgestellten und allen restlichen Szenarien sind im Anhang~\ref{cap:appendix} zu finden.
% \todo[inline]{hier könnte ich noch mehr schreiben zu verschiedenen anderen Szenarien, wenn es notwendig sein sollte.}
% \todo[inline]{NextStep Boxplot schön machen ohne titel und in mm}

\begin{figure}[htbp]
    \centering
	
	\begin{subfigure}[t]{0.8\textwidth}
		\includegraphics[width=\textwidth]{RealSpheres-evaluation_NextStep_LocationError_2018-12-10_18-42-20.pdf}
		\caption{Boxplots für die NextStep-Ergebnisse der selbst aufgenommenen Kugeln auf dem Förderband.}
		\label{subfig:RealSpheresBoxplot}
	\end{subfigure}
    % \quad
    \vskip\baselineskip
	\begin{subfigure}[t]{0.8\textwidth}
		\includegraphics[width=\textwidth]{SimulatedKugeln-evaluation_NextStep_LocationError_2018-12-17_15-28-43.pdf}
		\caption{Boxplots für die NextStep-Ergebnisse der Kugeln aus dem DEM-Datensatz.}
		\label{subfig:SimSpheresBoxplot}
	\end{subfigure}
	
    \caption[Visualisierung der Ergebnisse für die realen und simulierten Kugeln mit NextStep-Netzen]
    {Visualisierung der Ergebnisse für die realen und simulierten Kugeln mit NextStep-Netzen. Kleinere Werte sind besser.}
	\label{fig:BoxplotsNextStep}
\end{figure}

\begin{figure}[h]
    \centering
    % \missingfigure{Boxplots Result NeuralNets NextStep}
	\includegraphics[width=0.8\textwidth]{RealSpheres-evaluation_NextStep_ErrorHistogram_2018-12-10_18-42-20.pdf}
    \caption[Fehlerhistogramm für die NextStep-Ergebnisse der selbst aufgenommenen Kugeln auf dem Förderband]
    {Fehlerhistogramm für die NextStep-Ergebnisse der selbst aufgenommenen Kugeln auf dem Förderband.}
	\label{fig:RealSpheresHistogram}
\end{figure}




% Bemerkenswert schlecht war das Ergebnis allerdings bei dem DEM Zylinder Datensatz.
% Es konnte nicht abschließend geklärt werden warum dies der Fall ist, vorallem da die Ergebnisse auf den realen Zylindern, wie in Abbildung TODO zu sehen, deutlich besser waren. 
% Man könnte jedoch vermuten, dass es eine Kombination der folgende Umstände ist.
% Bei den Zylindern hängt ihre Bewegung und die Aufnahme von Bewegungsenergie vom Förderband mehr von ihrer Orientierung ab, als bei den anderen Schüttgütern.
% Diese ist nicht aus den Eingabefeatures ersichtlich - potenziell wäre es bei diesem Szenario also lohnenswert mehr als nur die Mittelpunkte als Feature zu betrachten.
% Die höhere Bandgeschwindigkeit in der Simulation als in den Realdaten könnte diesen Effekt verstärkt haben.
% Auch könnte die höhere Schüttgutdichte auf dem Förderband darauf einen Einfluss gehabt haben.



% \color{blue}
% - CV, CA
% - Ergebnis Netz

% Vergleich Realdaten und simulierte Daten.
% Realdaten mit ungefähr \SI{1.1}{\meter\per\second} während Simulierte mit \SI{1.5}{\metre\per\second} Bandgeschwindigkeit 

% \color{black}

\section{Separator}

% \color{blue}
% CV, CA quasi wie oben.
% zusätzlich: CVBC, AA und IA

% - Ergebnis NN
% \color{black}



In diesem Abschnitt sollen nun die Ergebnisse der Separator-Netze in verschiedenen Szenarien betrachtet werden.
% Im Gegensatz zu diesen können die beiden Labelelemente nicht in einem gemeinsamen Evaluationskriterium zusammengefasst werden.
Hier wird die zeitliche Abweichung vom prädizierten Zeitpunkt, an dem das Druckluftdüsenarray passiert wird, und die örtliche Abweichung des Schnittpunkts der Bahn des Partikels mit dem Druckluftdüsenarray separat betrachtet.
Wie bei den NextStep-Netzen werden ein Constant Velocity- und ein Constant Acceleration Modell 
als Vergleichsmodelle benutzt. 
Zusätzlich werden noch mehr Vergleichsmodelle hinzugezogen. 
Das Bias-Corrected Constant Velocity Modell liefert sowohl eine Prädiktion für die Zeit als auch für den Ort.
Die Average Acceleration und Identical Acceleration Modelle sind nur für die zeitliche Prädiktion ausgelegt und werden dementsprechend nur dort zum Vergleich herangezogen.

Die Evaluation wurde auf folgendem Szenario durchgeführt.
Als Trainingsdaten wurden nur das jeweils letzte Feature-Label-Paar eines Tracks benutzt, bevor das entsprechende Partikel die Prädiktionsphase verlässt.
% \todo{Hier weg und dafür in den Ausblick?}  
Für die DEM-Datensätze wurde von \(x \approx \SI{0.55}{\meter}\) nach \(x = \SI{0.70}{\meter}\) prädiziert, also ca. \SI{15}{\centi\meter} nach vorne.
Da der gesamte Bildausschnitt der selbst aufgenommenen Daten weniger als \SI{15}{\centi\meter} entlang der Bewegungsrichtung misst, musste diese Distanz reduziert werden.
Die auf den selbst gesammelten Daten trainierten Netze prädizieren von \(y \approx \SI{800}{\px}\) nach \(y = \SI{1550}{\px}\), also eine Distanz von ungefähr \SI{750}{\px}.
% \todo{hier umrechnung in cm dazumachen? ungefähr 4.5 cm}


Die Ergebnisse für den Separator-Fall werden als
\begin{align*}
    t\hitext{Err} &=  t\hitext{Pred} -  t\hitext{GT} \: ,\\
    \mathsf{y}\hitext{Err} &=  \mathsf{y}\hitext{Pred} -  \mathsf{y}\hitext{GT}
\end{align*}
definiert.
Im Gegensatz zu dem NextStep-Fall ist es nur bedingt sinnvoll diese Fehler zu einem Gesamtfehler zu kombinieren.
Zusätzlich ist das Vorzeichen der Fehler für die einzelnen Partikel hier relevant.
Für die zeitlichen Fehler bedeutet ein positiver Wert, 
dass das Teilchen früher den Druckluftdüsenarray passiert hat als von dem Modell vorhergesagt. 


Die Ergebnisse der neuronalen Netze für die Separator-Prädiktion sind auf allen Datensätzen besser als das CV-Modell, das CV-Modell und das CVBC-Modell.
% \todo{Reihenfolge? erst Daten dann schlussfolgerungen}
Auf den beiden simulierten Datensätzen sind die Ergebnisse marginal schlechter als das IA-Modell, 
aber deutlich besser als die der grundlegenden Modelle und des CVBC-Modells.
Dies ist in Abbildung~\ref{fig:BoxplotsSimCub} exemplarisch durch die Boxplots der simulierten Plättchen dargestellt.
Zunächst soll der zeitliche Fehler betrachtet werden.
Obwohl der Median des Prädiktionsfehlers des neuronalen Netzes einen kleinen, positiven Bias hat und das untere Quartil größer als 0 ist, sind die Ergebnisse deutlich besser als die des CVBC-Modells.
%  werden die Fehler des neuronalen Netzes komplett von denen des CVBC-Modells überdeckt.
Für die Ergebnisse des neuronalen Netzes liegt der Bereich zwischen den Quartilen komplett innerhalb des entsprechenden Bereichs von dem CVBC-Modell
Das CV- und das CA-Modell sind beide noch einmal bedeutend schlechter als das CVBC-Modell.
Das CV-Modell ist bezüglich seiner Verteilung erwartungsgemäß identisch zum CVBC-Modell, hat aber einen Bias von beinahe zwei ganzen Zeitschritten.
Im Vergleich dazu ist das CA-Modell zwar etwa genauso biasfrei wie das neuronale Netz, hat aber die mit Abstand größte Standardabweichung von allen Modellen.
Der Interquartilsabstands des CA-Modells ist größer als der Abstand zwischen den Whiskers der restlichen Modelle.
Das beste Modell in diesem Szenario ist das IA-Modell.
Es ist beinahe komplett biasfrei und hat die geringste Standardabweichung von allen Modellen.
Bei der Betrachtung des örtlichen Fehlers ist das CA-Modell tatsächlich besser als das CV- und das CVBC-Modell, aber dennoch deutlich schlechter als das neuronale Netz.
Alle diese Modelle sind beinahe biasfrei, aber der Interquartilsabstands der Ausgabe des neuronalen Netzes ist deutlich geringer. 

\begin{figure}[htbp]
    \centering
	
	\begin{subfigure}[t]{0.8\textwidth}
		\includegraphics[width=\textwidth]{SimCub-evaluation_Separator_TimeErrorBoxplot_2018-12-11_14-33-22.pdf}
		\caption{Boxplots des zeitlichen Fehlers für die Separator-Ergebnisse der Plättchen aus dem DEM-Datensatz.}
		\label{subfig:SimCubTimeBoxplot}
	\end{subfigure}
    % \quad
    \vskip\baselineskip
	\begin{subfigure}[t]{0.8\textwidth}
		\includegraphics[width=\textwidth]{SimCub-evaluation_Separator_LocationErrorBoxplot_2018-12-11_14-33-22.pdf}
		\caption{Boxplots des örtlichen Fehlers für die Separator-Ergebnisse der Plättchen aus dem DEM-Datensatz.}
		\label{subfig:SimCubLocBoxplot}
	\end{subfigure}
	
    \caption[Visualisierung der Ergebnisse für die Plättchen aus der DEM-Simulation]
    {Visualisierung der Ergebnisse für die Plättchen aus der DEM-Simulation. Ein betragsmäßig kleinerer Median und eine möglichst kleine Streuung sind besser.}
	\label{fig:BoxplotsSimCub}
\end{figure}

Im Vergleich dazu sind die Unterschiede zwischen den verschiedenen Modellen auf den selbst aufgenommenen Daten deutlich kleiner.
Das Constant Velocity Modell schneidet oft beinahe so gut,
und bei den Weizenkörnern sogar besser, ab als das Identical Acceleration Modell.
Auf den selbst gesammelten Daten schneidet von den bestehenden Modellen das Bias-Corrected Constant Velocity Modell am besten ab. 
Die neuronalen Netze sind jedoch noch einmal besser. 
Wenn man die Boxplots der zeitlichen Fehler der verschiedenen Modelle auf dem Weizenkörner-Datensatz der selbst aufgenommenen Daten, dargestellt in Abbildung~\ref{subfig:RealWeizenTimeBoxplot},
im Detail betrachtet gibt es einige Auffälligkeiten. 
Im Gegensatz zu dem Szenario, das in Abbildung~\ref{subfig:SimCubTimeBoxplot} dargestellt ist,
zeigt der zeitliche Fehler des CV-Modells nur einen geringen Bias, der sogar eher negativ ist.
Während es bei den simulierten Plättchen so ist, 
dass der Interquartilsabstands des CV-Modells um Faktoren größer ist als der des IA-Modells, ist er hier fast gleich groß.
Tatsächlich unterscheiden sich die Ergebnisse der CV-, CVBC-, AA- und IA-Modelle fast nur in ihrem Bias.
Dem gegenüber stehen die Ergebnisse des neuronalen Netzes, die fast komplett biasfrei sind und einen merklich kleineren Interquartilsabstand haben als jedes der bestehenden Modelle.
Ähnlich ist es beim örtlichen Fehler, der in Abbildung~\ref{subfig:RealWeizenLocBoxplot} dargestellt ist.
Die Ergebnisse des neuronalen Netzes einen kleinen Bias haben, der Bereich zwischen ihrem oberen und unteren Quartil wird jedoch immer noch komplett überdeckt von der Box des CVBC-Modells, das das Beste der Vergleichsmodelle ist.

% \todo[inline]{Resultat verifizieren}
Die Qualität der Resultate der bestehenden Modelle hängt höchstwahrscheinlich mit der niedrigeren Bandgeschwindigkeit und dem kürzeren Prädiktionsabstand zusammen.
Auch könnten die unterschiedlichen Verfahren unterschiedlich anfällig gegen das Messrauschen sein, das auf den simulierten Daten nicht existiert.
% Das CV- und das CA-Modell 
Für die bestehenden Modelle gilt, dass eine relative Verbesserung der zeitlichen Prädiktion zu einer Verbesserung der örtlichen Prädiktion führt,
da die zeitliche Prädiktion benutzt wird, um die örtliche zu bestimmen.
Das ist besonders gut in Abbildung~\ref{fig:BoxplotsSimCub} zu erkennen. 
Die Verbesserung der zeitlichen Prädiktion zwischen dem CV- und dem CVBC-Modell, zu sehen in Abbildung~\ref{subfig:SimCubTimeBoxplot}, sorgt auch direkt für eine Verbesserung der örtlichen Prädiktion, zu sehen in Abbildung~\ref{subfig:SimCubLocBoxplot}.
Für die Ausgabe der neuronalen Netze gilt das jedoch nicht. Hier werden beide Ausgaben gemeinsam bestimmt.
Wie für die NextStep-Netze sind die Boxplots aller Szenarien im Anhang~\ref{cap:appendix} zu finden.

\begin{figure}[htbp]
    \centering
	
	\begin{subfigure}[t]{0.8\textwidth}
		\includegraphics[width=\textwidth]{RealWeizen-evaluation_Separator_TimeErrorBoxplot_2018-12-11_14-09-12.pdf}
		\caption{Boxplots des zeitlichen Fehlers für die Separator-Ergebnisse des Weizenkörnern-Datensatz von den selbst gesammelten Daten.}
		\label{subfig:RealWeizenTimeBoxplot}
	\end{subfigure}
    % \quad
    \vskip\baselineskip
	\begin{subfigure}[t]{0.8\textwidth}
		\includegraphics[width=\textwidth]{RealWeizen-evaluation_Separator_LocationErrorBoxplot_2018-12-11_14-09-12.pdf}
		\caption{Boxplots des örtlichen Fehlers für die Separator-Ergebnisse des Weizenkörnern-Datensatz von den selbst gesammelten Daten.}
		\label{subfig:RealWeizenLocBoxplot}
	\end{subfigure}
	
    \caption[Visualisierung der Ergebnisse für den Weizenkörnern-Datensatz von den selbst gesammelten Daten.]
    {Visualisierung der Ergebnisse für den Weizenkörnern-Datensatz von den selbst gesammelten Daten. Ein betragsmäßig kleinerer Median und möglichst kleine Streuung sind besser.}
	\label{fig:BoxplotsRealWeizen}
\end{figure}


\section{Zusammenfassung und Diskussion}

% \todo[inline]{Einleitung und Zusammenfassung}

Die Tatsache, dass die Separator-Netze auf den DEM-Datensätzen, im Gegensatz zu allen anderen Szenarien,
hinter dem aktuellen Stand der Technik zurückbleiben könnte darauf zurückzuführen sein, 
dass dort verhältnismäßig wenig Trainingsdaten zur Verfügung standen.
Wie bereits in Kapitel~\ref{cap:data} erwähnt, haben DEM-Datensätze im Vergleich zu den selbst aufgenommenen Daten weniger, aber dafür deutlich längere Tracks.
Für die NextStep-Netze sorgt die größere Länge dazu, dass sogar mehr Feature-Label-Paare aus den DEM-Daten extrahiert werden können als aus den selbst aufgenommenen.
Für die Separator Netze ist die Länge der Tracks jedoch unerheblich.
Aus einem Track entsteht nur ein einzelnes Feature-Label-Paar.
Es konnten mit den aufgenommenen Daten und der verwendeten Datenaugmentierung Ergebnisse erzielt werden, die an den aktuellen Stand der Technik herankommen.
Um diesen zu übertreffen scheint es so, als ob mehr Trainingsdaten benötigt werden.
% Ein ähnliches Problem Problem [... Rutsche]


In der Zukunft wäre es wünschenswert, ein präziseres Hyperparameter-Tuning für mehr Szenarien durchzuführen.
Wie in Abschnitt~\ref{sec:hypp} beschrieben, wurden nur zwei Hyperparameter-Konfigurationen optimiert, was jeweils auf dem DEM-Kugel-Datensatz durchgeführt wurde.
Diese Konfigurationen, eine für NextStep-Netze und eine für Separator-Netze, wurden dann für alle verschiedenen Szenarien benutzt.
Auch wenn es ein beträchtlicher Zeitaufwand wäre, hätte individuelles Hyperparameter-Tuning für die einzelnen Schüttgutsorten wahrscheinlich einen positiven Effekt auf die Güte der Ergebnisse.
Insbesondere ist es so, dass das Ergebnis für die Separator-Netze nicht gut auf die Rutschenkonfiguration des \textit{TableSort}-Systems anwendbar war.
Die Partikel bewegen sich in dieser Konfiguration deutlich schneller als auf dem Förderband, weshalb weniger Beobachtungen pro Track im Sichtbereich der Kamera gemacht werden.
Eine FeatureSize von 7, wie von der Hyperparameter-Konfiguration für Separator-Netze vorgesehen, ist bei einer durchschnittlichen Tracklänge von 10 nicht sinnvoll.

% Es wäre in der Zukunft möglich auf allen möglichen Feature-Label-Paaren zu trainieren, um zu erreichen, dass der Ausgangspunkt verschoben werden kann ohne das Netz neu trainieren zu müssen.
% \todo[inline]{Hier über möglichkeit reden auf ganzen Tracks für separator lernen?}


Es konnte beobachtet werden, dass bei mehrmaligem Trainieren eines Netzes 
mit identischen Hyperparametern und Daten unterschiedliche Ergebnisse mit einem ähnlichen MSE insgesamt aber einer Verschiebung zwischen dem Mittelwert und der Standardabweichung  
an dessen Ende standen.
Für Separator-Netze kam es sogar zu Verschiebungen zwischen der örtlichen und der zeitlichen Prädiktion.
Das Fehlermaß, nach der die neuronalen Netze optimiert worden sind, ist der MSE, wonach zwei Ergebnisse mit identischem MSE gleichwertig sind, egal wie dieser zustande kommt.
Dies ist auf verschiedene stochastische Vorgänge während dem Training zurückzuführen, wie die Initialisierung der Gewichte zwischen den Neuronen und die Reihenfolge beziehungsweise das Batching der Trainingsbeispiele.
Der Einsatz einer anderen Fehlerfunktion, zum Beispiel einer, die tatsächlich den Anteil der korrekt separierten Teilchen bewertet, könnte dieses Problem beheben.
Für die Zukunft könnte im Separator-Fall das Auftrennen der zeitlichen und der örtlichen Prädiktion in unterschiedliche Netze sinnvoll sein.
% \todo[inline]{den Ganzen Absatz weglassen? So wirklich was trägt er nicht bei zum Ergebnis und er steht ohne daten da auch sehr allein da.}
